%!TEX root = ../main.tex

\chapter{轻量级热点识别机制设计与实现}
\label{ch:hotspot}

在资源受限的嵌入式虚拟化环境中，准确且高效地识别内存中的“热点页”（Hot Pages）是优化快照性能的先决条件。若能精准区分频繁修改的热点页面与相对稳定的冷页面，在快照的停机阶段（Stop-Phase）优先处理热点，而在后台阶段（Post-Phase）处理冷页面，就能有效避免预拷贝阶段的无效迭代和后拷贝阶段的频繁缺页异常。然而，传统的LRU算法或基于全量写保护的追踪机制在计算能力与内存受限的设备上开销过大。本章将详细阐述一种基于硬件辅助访问位与多级感知策略的轻量级热点识别机制，旨在以极低的系统损耗实现对内存访问时空局部性的精准捕捉。

\section{内存访问的时空局部性特征分析}

为了构建高效的热点感知算法，首先需要在真实的边缘计算与嵌入式虚拟化环境中，对典型工作负载的内存写入行为进行系统性的定性和定量分析。本研究选取了7种具有代表性的异构应用，包括空闲任务（Idle）、数据库读写（SQLite）、数据压缩工具（7zip）、缓存系统（Memcached）、计算机视觉处理库（OpenCV）、实时目标检测框架（YOLO）以及轻量级大语言模型推理场景（ TinyLlama）。通过对这些工作负载在快照预拷贝阶段的页脏化行为进行长周期追踪，可以清晰地观察到边缘虚拟化环境中普遍存在的三个关键访问特征：冷热分布高度偏斜、热点区域漂移迅速以及负载规模呈现强烈的波动性。

通过对这些工作负载在预拷贝阶段产生的脏页（Page Dirty Counts）进行统计与可视化分析，我们发现资源受限虚拟化平台中的内存访问模式远非均匀随机，而是呈现出显著的、跨负载一致的时空局部性特征（Spatio-Temporal Locality）。这些特征不仅揭示了内存写入行为的潜在规律，也为后续热点识别机制提供了关键的理论支撑。本节将从以下四个方面展开论述。

\subsection{极度偏斜的冷热分布（Zipf-like Distribution）}

实验结果表明，内存写入的空间分布具有显著的极度偏斜特征，类似于齐夫分布（Zipf-like Distribution）。在多数快照周期中，大部分页面在整个执行过程内几乎没有写入活动，而仅有极少量页面承担了主要的写入操作。换言之，系统的写入负载高度集中在一个体量较小但活跃度极高的工作集内部。例如，在 YOLO 推理、TinyLlama 推理以及 Redis 请求处理等场景中，不变的数据结构（如模型权重、只读表项）几乎不会被修改，而输入缓冲区、输出缓存、临时工作区等区域则持续保持着高写入速率。

这种极度偏斜的冷热分布对快照系统具有重要启示：若快照算法对所有页面采取完全均匀的处理策略，将导致大量冗余扫描与重复拷贝，极大拉长停机时间。而只要能够精准识别并锁定占比极小的高写入页面，就能以很低的性能代价解决大部分数据一致性问题，从而显著降低快照停机阶段的时延。这一特征为轻量级热点感知机制的设计提供了明确方向，即热点页面的识别不需要全局扫描，只需以低成本捕捉活跃度高度集中的小型核心区域。

\subsection{快速且剧烈的热点漂移（Rapid Hotspot Drift）}

尽管热点区域的规模相对较小，但其位置并非稳定不变，而是会随着工作负载的阶段性变化而快速漂移。边缘设备上的应用往往具有多阶段的执行流程，例如在计算机视觉场景中，系统会在图像预处理、卷积计算、特征融合和结果输出等不同阶段之间不断切换，从而导致热点页面在极短时间内从某一内存区域跳转至另一区域。在 AI 推理和图像处理应用中，这种漂移现象尤为明显：上一时刻频繁写入的区域可能在下一时刻完全冷却，而新的子任务则会迅速产生新的高频写入点。

快速漂移的出现使得依赖长周期窗口统计或简单频度累积的热点推断机制难以发挥作用。传统方法容易出现“滞后性”：当系统完成热点识别并采取相应策略时，热点可能早已发生迁移，从而导致识别失准和带宽浪费。因此，热点识别机制必须具备较高的响应速度，能够捕捉到毫秒级甚至更精细时间尺度上的热点跳变，并在快照不同阶段快速调整优先级，否则无法适应边缘场景中的瞬态访问特征。

\subsection{大幅度的负载波动（Large Load Fluctuations）}

除了空间位置与热点区域的动态变化外，内存脏页产生速率本身也在时间轴上表现出强烈波动。计算类任务（如 7zip 压缩和 YOLO 推理）启动时，写入速率会骤然上升，瞬间可能超过底层存储介质的可持续写入带宽；而在系统等待外部事件、传感器输入或网络数据的间歇阶段，脏页产生速率又会降至极低水平，甚至趋近于零。这种“峰谷交替”的写入行为意味着快照系统若采取静态策略，势必在高负载时期面临严重的写入拥塞与重复拷贝，而在低负载时期未能充分利用空闲带宽。

因此，一个高效的热点识别策略必须能够感知当前负载压力，并根据脏页产生速率的实时变化动态调整判断标准。例如，在写入高峰期，更严格的热点过滤能减少冗余写入，避免快照过程与前台业务争抢带宽；而在负载低谷期，系统则可以适当扩大热点识别范围，将更多页面提前处理，从而缩短停机窗口并提高整体吞吐。

\subsection{资源受限环境下的采样悖论}

尽管理论上可以通过频繁采样与复杂统计模型捕捉上述三种特性，但在边缘设备中，由于 CPU 与内存资源有限，难以承受高频的页表扫描、写保护开销或复杂链表维护。更高的采样频率会显著增加计算负载和内存带宽占用，使得监控过程本身成为额外的系统压力来源，甚至可能对前台业务造成干扰。换言之，过于复杂的热点追踪机制会与轻量化、低开销的设计目标直接冲突。

因此，边缘虚拟化场景面临一个典型的“采样悖论”：识别热点需要高频采样，但高频采样又在资源受限环境中不可行。这一矛盾迫使我们必须寻求一种新的设计路径，在极低的资源消耗下仍能精准刻画内存访问的局部性特征。

\section{基于硬件辅助访问位的双位老化算法}

针对4.1节中论述的边缘环境下“采样悖论”——即高频热点追踪需求与有限计算资源之间的矛盾，本研究摒弃了传统虚拟化中基于“写保护-异常陷入”（Write Protection \& VM Exit）的重型追踪方案。我们提出了一种轻量级的、软硬协同的双位老化算法（Double-Bit Aging Algorithm）。该算法利用现代处理器内存管理单元（MMU）的硬件特性作为低开销传感器，结合极简的位运算逻辑构建状态机，在不中断虚拟机执行流的前提下，实现了对内存页面访问热度的精准量化与分级。

\subsection{传统追踪机制在受限环境下的失效分析}

在详细阐述本研究提出的双位老化算法之前，有必要深入分析传统脏页追踪机制在资源受限环境下的性能瓶颈。以 KVM 为代表的主流虚拟化平台中，常见的内存追踪方法如 Log-Dirty 模式主要依赖页表写保护机制。其基本流程是：Hypervisor 将客户机物理页（GPA）标记为只读，当 Guest OS 尝试写入页面时，会触发扩展页表异常（EPT Violation），导致 VM Exit。CPU 陷入 Host 模式后，Hypervisor 需要保存寄存器状态、刷新 TLB、更新脏页位图，并最终恢复权限，再返回 Guest 执行。

这种机制在服务器级平台上能够提供高精度的写入记录，但在嵌入式或边缘设备上存在以下两个显著缺陷：

\begin{itemize}
\item \textbf{昂贵的上下文切换开销：}
在嵌入式处理器（如 ARM Cortex-A 系列）中，处理器主频相对较低，流水线较短，乱序执行和缓存容量有限。每次 VM Exit 都需要进行寄存器保存、TLB 刷新、页表状态恢复以及可能的 L1/L2 缓存污染。这意味着，当 Guest 执行写密集型任务（如 4.1 节提到的 YOLO 推理、7zip 压缩或其他计算密集型算法）时，频繁的页面写入将引发大量陷入事件，形成所谓的“中断风暴”。这一风暴不仅增加 CPU 的调度压力，而且直接占用执行时间，使业务逻辑的前台计算被迫等待 Hypervisor 处理完成后才能继续执行，从而显著延长快照停机时间，并可能导致前台任务的缓存局部性和流水线连续性受到破坏。换句话说，这种机制在资源受限环境中本身就是性能瓶颈，其代价随写入频率上升呈指数级增长。

\item \textbf{用户态与内核态通信瓶颈：}
在 QEMU/KVM 架构下，用户态的 QEMU 进程需要通过 \texttt{ioctl} 或类似系统调用与内核态同步脏页位图。每一次同步都涉及内核态与用户态之间的上下文切换和数据拷贝，这在资源受限的嵌入式设备上开销极高。当内存访问速率较高时，系统调用频繁出现，可能占据可观的 CPU 周期，导致前台业务计算被迫等待。此外，由于热点页面可能在毫秒级时间尺度上快速漂移，高延迟的位图同步无法及时反映热点变化，使得基于这种同步的脏页追踪策略在边缘场景下难以实现实时性。换句话说，即便追踪机制在逻辑上可行，其实际响应速度也无法满足热点识别所需的高时效性要求。

\end{itemize}

因此，要在边缘设备上实现高效的热点识别，必须切断“写入行为”与“异常中断”之间的强绑定关系，探索一种非侵入式、低开销、可实时捕捉热点的监测手段。这为本文提出的硬件辅助双位老化算法提供了理论基础与设计动机，使得热点追踪能够在保证 Guest 执行连续性的前提下，获得更高的精度与更低的系统开销。

\subsection{硬件辅助的无感监测机制}

为解决传统脏页追踪在边缘设备上的高开销与低响应问题，本研究提出利用处理器硬件提供的访问位特性，构建低开销的无感监测机制。该机制通过软硬协同，将高频异常中断转换为可控的低频轮询过程，从而在不干扰 Guest 执行的前提下，实现对页面访问行为的精准感知。具体设计可以概括为以下几个核心部分：

\begin{itemize}

\item \textbf{硬件访问位作为零开销传感器：}
现代处理器（如 x86 架构的 Accessed Bit，ARMv8.1 架构的 AF Bit）在页表项中维护访问位，当页面被 CPU 读写时，MMU 会自动将访问位置 1。此过程由硬件流水线完成，无需软件干预，也不会触发 VM Exit 或中断。这意味着访问位本身可以作为一种低成本、零延迟的页面访问传感器，能够捕捉页面在每个时间片内的访问情况，而不会对前台业务造成任何性能干扰。相较于传统写保护机制依赖异常陷入的方法，访问位提供了连续、稳定且可原子读取的访问信息，为后续热度计算奠定了基础。

\item \textbf{时间驱动的内核扫描策略：}
基于硬件访问位，本研究设计了一个低优先级内核扫描器，周期性遍历虚拟机物理内存对应的页表项。与传统事件驱动的写保护机制不同，扫描器采用固定时间窗口进行轮询，例如每 200ms 扫描一次。扫描器在读取访问位后立即将其清零，使硬件能够在下一周期重新捕捉页面访问行为。通过这种方式，系统将原本由高频异常触发的写入检测转化为可控的定期采样，不仅避免了“中断风暴”，而且使扫描开销与 Guest 的写入压力解耦，从而在高负载下保持恒定性能。

\item \textbf{连续热度捕捉与状态演化：}
访问位提供了页面在当前时间片内是否被访问的二值信息，但为实现细粒度的热点感知，需要进一步对历史访问行为进行建模。本机制在扫描器层维护页面热度状态，通过位移与衰减操作，将连续周期的访问信息累积到页面热度指标中。这种设计能够将简单的访问位信号转化为连续的热度度量，使系统能够区分瞬时访问与长期高频访问，进而精确区分热点页面与冷页面。连续热度的捕捉机制兼顾了响应速度与历史趋势，适应了边缘负载中热点漂移快速、访问波动剧烈的特征。

\item \textbf{非侵入式执行与系统透明性：}
扫描器和热度更新机制完全运行在 Host 内核态，并以低优先级执行。由于不依赖写保护陷入或异常处理，Guest 的执行路径不会被中断，前台业务的缓存局部性和流水线连续性得以保留。同时，该机制不会引入额外的中断或系统调用开销，确保在负载高峰期的快照操作对业务性能影响最小。这种非侵入式设计为嵌入式环境下的实时热点追踪提供了可行方案。

\item \textbf{适应负载波动的动态调节能力：}
边缘场景下，内存脏页产生率在时间轴上呈现强烈波动，高峰期可能瞬间超出存储带宽，而低谷期又会出现空闲带宽。基于访问位和双位老化状态，系统可以动态调整热点判定阈值或扫描周期，以适应当前负载压力。在高负载阶段，提高热点过滤精度以避免存储拥塞；在低负载阶段，可适当放宽判定标准，将更多页面提前处理，从而充分利用空闲带宽。这种自适应能力保证了热点识别机制在不同业务阶段都能高效工作。

\end{itemize}

这种机制将不可控的高频异常中断转化为可控的低频轮询开销。在 4.1 节提到的高负载波动场景下，即使前台业务的内存写入速率极高，扫描器的开销依然保持恒定，从而彻底避免了对业务性能的抖动干扰。为后续双位老化算法提供了可靠、连续的访问信息，使得热点页面能够在停机阶段优先处理，并在后台阶段合理调度冷页面，从而最大化降低快照停机时间，同时保证前台业务性能。

\section{双位老化页面分类算法}

在资源受限的嵌入式虚拟化环境中，仅仅依赖单次扫描获取页面的访问位（0 或 1）并不能准确反映页面的长期热度。这是因为单次访问只能告诉我们页面是否被访问过，但无法区分“偶尔访问”的页面和“持续高频访问”的页面。而传统的解决方案，例如 LRU 算法，通常需要维护复杂的链表或队列结构，用于记录页面的访问历史。然而，在内存容量仅有 1GB 到 4GB 的嵌入式设备上，这类元数据的管理开销过大，不适合实时高效的热点识别。

为了解决这个问题，本研究提出了一种双位老化算法。该算法不需要维护复杂的数据结构，每个物理页面只需分配两个比特位，就可以在极小的内存占用下模拟页面访问的时间衰减特性。我们将每个页面的状态用一个两位二进制数表示，记为$S_{page} \in \{00, 01, 10, 11\}_2$。其中，高位表示历史访问状态，用于记录上一周期或更久远的访问累积信息，反映页面的时间局部性；低位表示当前周期的访问状态，反映页面的即时活跃度。通过这种双位表示，每个页面既能记录当前的访问情况，也能保留短期的历史访问信息，从而实现轻量化的热度追踪。在每个扫描周期结束时，算法对每个页面执行状态更新。状态更新的逻辑可以用如下公式表示：
\[
S_{\mathrm{new}} = \bigl( (S_{\mathrm{old}} \mathbin{\&} 0x1) \ll 1 \bigr) \mathbin{|} H_{\mathrm{bit}}
\]
。其中，$S_{old}$ 为页面在上一周期的状态，$H_{bit}$ 为从 PTE 读取的硬件访问位（1 表示被访问，0 表示未访问）。该公式包含三个关键步骤：

\textbf{（1）老化（Aging）}：老化操作由表达式 $\bigl( (S_{\mathrm{old}} \mathbin{\&} 0x1) \ll 1 \bigr)$ 实现，其机制在于模拟页面访问热度的自然时间衰减过程。首先，通过位掩码操作 $\mathbin{\&} 0x1$ 提取 $S_{\mathrm{old}}$ 的最低位。在双位算法中，$S_{\mathrm{old}}$ 的低位代表着上一监测周期页面是否被访问的状态，即其新鲜度（Recency）。后，将提取出的低位状态左移一位，使其占据新状态 $S_{\mathrm{new}}$ 的高位。这一操作是老化机制的核心：它将页面在上一周期的“当前”访问状态转化为新周期的“历史”访问记录。如果页面在上一周期是活跃的，则 $S_{\mathrm{new}}$ 的高位被置为 1；否则为 0。这种位移逻辑确保了访问信息的时效性衰减，符合内存访问局部性随时间推移而降低的客观规律。

\textbf{（2）更新（Update）}：更新操作由表达式 $\dots \mid H_{\mathrm{bit}}$ 完成，旨在将页面在当前监测周期内的最新访问事实纳入状态追踪。在状态迭代开始前，内核扫描线程从 $H_{\mathrm{bit}}$ 硬件寄存器中获取本周期的访问状态。由于 $H_{\mathrm{bit}}$ 在读取后被 Hypervisor 清零，它精确反映了当前监测周期内页面的访问行为。通过位或操作 $\mid H_{\mathrm{bit}}$，将最新的硬件访问状态 $H_{\mathrm{bit}}$ 直接填充到 $S_{\mathrm{new}}$ 的最低位。如果页面在本周期内被访问，则 $H_{\mathrm{bit}}=1$，新状态的低位被置为 1，表明该页面在当前时刻是活跃的；反之，若 $H_{\mathrm{bit}}=0$，低位为 0。此操作确保了状态值 $S_{\mathrm{new}}$ 的低位始终反映最新的瞬时访问活跃度。

\textbf{（3）迭代（Iteration）}：经过老化和更新两步操作后，新的状态 $S_{\mathrm{new}}$ 包含了一个关于页面访问历史的滑动窗口记录。新状态 $S_{\mathrm{new}}$ 将在下一监测周期替代 $S_{\mathrm{old}}$ 参与计算。通过周期性的迭代，双位状态 $S$ 能够以 $2^2=4$ 种组合（00、01、10、11）精确表征页面的访问频率与访问新鲜度之间的关系。状态 $S_{\mathrm{new}}$ 的值越高（例如从 $00 \to 11$），表明该页面在近期和历史周期内都保持了较高的活跃度，即其访问热度高。反之，若状态值持续处于低位（例如 $00$），则表明该页面处于冷寂状态。这种机制以极小的内存开销（每页仅 2 bit）实现了对内存页访问热度的有效量化与实时追踪。


这种位运算逻辑极其简单，在 ARM 处理器上仅需数个指令周期即可完成，且不需要分配额外的内存对象，非常适合资源受限环境。通过双位老化算法，每个页面的状态可以映射为三种热度等级，这些等级可以直接指导快照系统采取差异化的处理策略，从而实现对热点页面的精确调度。具体而言：

\begin{itemize}
\item \textbf{极热页面（Hot Page, State = 11）}：表示该页面连续两个扫描周期均被访问，属于持续高频访问的页面。在边缘负载环境中，这类页面通常只占总内存的 1\%-10\%，却承担了绝大部分写入操作。由于其访问非常频繁，如果在预拷贝阶段就尝试传输这些页面，很可能传输完成后页面已经再次被修改，导致重复写入和带宽浪费。因此，对于极热页面，快照系统会选择在停机阶段一次性保存，或者配合写合并机制在内存中暂存，最大程度减少无效 I/O。

\item \textbf{温热页面（Warm Page, State = 01 或 10）}：表示最近两个周期内页面只被访问一次。状态为 01 时，页面刚刚从冷状态变热，可能处于热点漂移的迁入期；状态为 10 时，页面曾经是热点，但本周期未被访问，可能处于冷却期。这类页面状态不稳定，快照系统需要特别关注。在快照过程中，这类页面会启用写时复制机制，一旦发生写入就立即捕获副本，以防止数据丢失或不一致。

\item \textbf{冷寂页面（Cold Page, State = 00）}：表示连续两个周期内页面未被访问，这类页面占据了绝大部分内存（通常超过 80\%），例如代码段、只读数据区等。由于其访问极少，数据高度稳定，快照系统可以将其标记为安全区域，在后台阶段低优先级传输。由于这些页面几乎不会被修改，后台传输过程中几乎无需重传脏页，从而显著节约 I/O 带宽。
\end{itemize}

通过双位老化状态机，系统将复杂的内存访问模式（包括 Zipf 分布的热点、快速漂移和负载波动）映射为三种可操作的状态，实现了“访问频率量化 + 热度分级 + 快照策略映射”的闭环。相比传统的全量扫描方法，该机制能够将计算和 I/O 资源集中在少数关键页面上，从而在降低快照停机时间的同时，最大程度保证前台业务性能。

\section{多级工作集感知策略}

虽然双位老化算法能够有效地对内存页面进行热度分类，但在快照启动初期，由于历史访问信息尚不足，仅依赖单周期采样往往无法捕获全部潜在的热点页面。这可能导致预拷贝阶段的迭代收敛缓慢，增加脏页重传次数，降低快照效率。针对这一问题，本研究引入了多级工作集感知策略，将热点识别过程划分为三个阶段，并根据信息积累程度动态调整热点判定的激进程度，从而在保证准确性的同时，加快工作集收敛。

\textbf{阶段1：基于局部性的激进预测}

在快照启动的初始几个监测周期内，系统对内存访问模式的了解仍非常有限。为了防止潜在热点遗漏导致后续迭代产生大量脏页，本阶段采用“宁滥勿缺”的激进策略，充分利用内存的空间局部性原理。当检测到某页面 $P_i$ 的访问位为 1 时，不仅将 $P_i$ 标记为热点，还将其物理地址相邻的页面 $P_{i-1}$ 与 $P_{i+1}$ 视为潜在热点，并将相应的计数器更新：
\[
Count(P_i) \leftarrow Count(P_i) + 1, \quad 
Count(P_{i-1}), Count(P_{i+1}) \leftarrow Count(P_{i-1}) + 1, Count(P_{i+1}) + 1
\]
这一策略的依据在于，在数组处理、矩阵运算或连续数据块访问的场景中，相邻页面极有可能被短时间内连续访问。通过激进捕捉，可以快速覆盖潜在工作集，避免热点遗漏并减少预拷贝初期迭代次数。

\textbf{阶段2：精确追踪}

随着监测周期的推进，系统已经积累了足够的访问信息，能够对页面热度做出初步判断。如果继续将邻近页面作为潜在热点，会导致热点集合虚高，增加无效传输。因此，系统会自动切换至精确追踪模式。在该模式下，仅对实际检测到硬件访问位为 1 的页面执行热度累加：
\[
\text{若 } H_{\mathrm{bit}}(P_i)=1, \quad Count(P_i) \leftarrow Count(P_i) + 1
\]
此模式取消了邻近页面的模糊推测，确保热点集合更加精确。系统在完成一次全内存扫描（即一轮预拷贝迭代）后，由 Mode 1 自动切换至 Mode 2，使热点识别过程逐步收敛。

\textbf{阶段3：老化与收敛}

在预拷贝阶段后期，为了处理曾经活跃但近期未访问的“过时热点”，必须引入老化与衰减机制，使工作集大小逐渐收敛，从而触发停机条件。在该阶段，若页面 $P_i$ 的访问位 $H_{\mathrm{bit}}(P_i)=1$，则计数器 $Count(P_i)$ 增加；反之，若 $H_{\mathrm{bit}}(P_i)=0$，则计数器减一，最小减至 0。  系统实时监控工作集的大小变化，当连续几个周期内变化率低于 10\% 时，表明热点集合已经趋于稳定。此时，系统判定预拷贝阶段结束，并立即进入停机快照阶段，将当前锁定的极热页面一次性保存至存储介质。这一机制既保证了热点捕获的完整性，又有效避免了不必要的重复拷贝，从而提升快照效率并降低对前台业务的干扰。

\section{高效内核态实现与优化}

为了确保前述双位老化算法及多级工作集感知策略在嵌入式设备上的高效执行，本研究在实现层面进行了深度优化，构建了一套高性能的内核态与用户态交互机制，从而最大限度地降低 CPU 开销和内存访问延迟。

\subsection{共享内存热度位图}

在标准的 KVM 虚拟化架构中，用户态 QEMU 进程获取虚拟机脏页信息通常依赖于 \texttt{ioctl(KVM\_GET\_DIRTY\_LOG)} 系统调用。然而，在高频扫描场景下，频繁的系统调用会带来显著的上下文切换开销（Context Switch Overhead），严重影响前台业务性能。

为此，本研究在 KVM 内核模块中对 \texttt{kvm\_memory\_slot} 结构进行了扩展，增加了一个热度位图（Heat Bitmap）。通过 Linux 的 \texttt{mmap} 机制，将这块内核物理内存直接映射到 QEMU 用户态虚拟地址空间，实现了内核与用户态的共享访问。

在这一设计中，内核态职责是扫描线程周期性遍历页表，读取硬件访问位（Access Bit），并直接在热度位图上更新页面状态（00/01/10/11），完成热度信息的量化。用户态职责是快照决策线程无需通过系统调用获取脏页信息，而是直接读取映射的共享内存区域，获取最新的页面热度分布，用于动态调整预拷贝和停机阶段的传输策略。该机制完全消除了数据拷贝和高频系统调用，实现了零拷贝（Zero-Copy）的数据传递方式，从而显著提升了热点识别与快照决策的执行效率。

\subsection{无锁并发控制}

由于内核扫描线程（生产者）与用户态决策线程（消费者）同时运行，必须保证对热度位图的访问一致性。为了避免传统锁机制导致的 CPU 流水线停顿和性能下降，本研究采用无锁编程技术，实现高效并发控制：

\begin{itemize}
    \item \textbf{原子操作}：内核线程在更新热度位图状态时，使用原子指令（Atomic Instructions）确保状态位的读-改-写过程不可分割，避免竞争条件。
    \item \textbf{RCU 机制}：利用 Linux 内核的 RCU（Read-Copy-Update）机制保护内存槽元数据，在热度位图扩容或销毁时保证并发安全，同时允许用户态线程在无需阻塞的情况下读取数据。
\end{itemize}

通过共享内存与无锁同步的结合，本研究实现了高频访问热度采集与快照策略决策的并行化，使双位老化算法在资源受限的嵌入式环境下能够以最小的性能开销运行，同时保证数据一致性和实时性。

\section{本章小结}

本章针对资源受限环境下虚拟化快照面临的“采样悖论”与热点漂移挑战，提出了一套软硬协同的轻量级热点识别机制。
首先，通过对典型边缘工作负载的深入分析，揭示了内存访问呈现出的显著 Zipf 分布与时空局部性特征，明确了以极低开销锁定核心工作集的可行性。
其次，本章摒弃了高昂的写保护追踪方案，创新性地设计了基于硬件辅助访问位的双位老化算法。该算法利用 2-bit 状态机模型，在不中断虚拟机运行的前提下，模拟了时间维度的热度衰减，成功将页面划分为极热、温热与冷寂三个层级，为快照策略的差异化调度提供了精准依据 。
再次，为了克服热点识别初期的滞后性，引入了多级工作集感知策略，通过从激进的空间邻近推测到精确的时间老化追踪的动态切换，确保了预拷贝阶段脏页集合的快速收敛 。
最后，在系统实现层面，通过内核共享内存与无锁同步机制，实现了用户态与内核态的零拷贝交互，显著降低了监控过程的系统损耗 。本章的研究成果为后续章节构建基于资源反馈的动态快照决策模型提供了实时、可靠的数据支撑。

