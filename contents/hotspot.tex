%!TEX root = ../main.tex

\chapter{轻量级热点识别机制设计与实现}
\label{ch:hotspot}

在资源受限的嵌入式边缘虚拟化环境中，准确且高效地识别内存中的“热点页”是优化快照性能的先决条件。若能精准区分频繁修改的热点页面与相对稳定的冷页面，在快照的停机阶段优先处理热点，而在后台阶段处理冷页面，就能有效避免预拷贝阶段的无效迭代和后拷贝阶段的频繁缺页异常。然而，传统的LRU算法\cite{o1993lru}或基于全量写保护的追踪机制在计算能力与内存受限的设备上开销过大。本章将详细阐述一种基于硬件辅助脏位与两阶段感知策略的轻量级热点识别机制，旨在以极低的系统损耗实现对内存写入时空局部性的精准捕捉。

\section{内存写入的时空局部性特征分析}
\label{sec:feature}

为了构建高效的热点感知算法，首先需要在真实的嵌入式边缘虚拟化环境中，对典型工作负载的内存写入行为进行系统性的定性和定量分析。本研究选取了6种具有代表性的异构应用，包括空闲任务、数据库读写（SQLite\cite{bhosale2015sqlite}）、数据压缩（7zip\cite{7zip}）、计算机视觉处理库（OpenCV\cite{bradski2000opencv}）、实时目标检测框架（YOLO\cite{wang2023yolov7}）以及轻量级大语言模型推理场景（TinyLlama\cite{zhang2024tinyllama}）。通过对这些工作负载在快照预拷贝阶段的页脏化行为进行长周期追踪，可以清晰地观察到边缘虚拟化环境中普遍存在的三个关键特征：冷热分布高度偏斜、热点区域漂移迅速以及负载规模呈现强烈的波动性。

通过对这些工作负载在预拷贝阶段产生的脏页进行统计与可视化分析，我们发现资源受限虚拟化平台中的内存写入模式远非均匀随机，而是呈现出显著的、跨负载一致的时空局部性特征。这些特征不仅揭示了内存写入行为的潜在规律，也为后续热点识别机制提供了关键的理论支撑。本节将从以下四个方面展开论述。

\subsection{极度偏斜的冷热分布}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/py/zipf.pdf}
    \caption{典型负载内存写入频度分布}
    \label{fig:zipf}
\end{figure}

实验结果表明，内存写入的空间分布具有显著的极度偏斜特征，类似于齐夫分布（Zipf-like Distribution）。如图\ref{fig:zipf}所示，对于大部分的负载，内存页面较大的一部分是冷页面，较小的一部分是热页面，极少的部分位于中间部分。即在多数快照周期中，大部分页面在整个执行过程内几乎没有写入活动，而仅有极少量页面承担了主要的写入操作。换言之，系统的写入负载高度集中在一个体量较小但活跃度极高的工作集内部。例如，在 YOLO 推理、TinyLlama 推理以及 SQLite 请求处理等场景中，不变的数据结构（如模型权重、只读表项）几乎不会被修改，而输入缓冲区、输出缓存、临时工作区等区域则持续保持着高写入速率。

这种极度偏斜的冷热分布对快照系统具有重要启示：若快照算法对所有页面采取完全均匀的处理策略，将导致大量冗余扫描与重复拷贝，极大拉长停机时间。而只要能够精准识别并锁定占比极小的高写入页面，就能以很低的性能代价解决大部分数据一致性问题，从而显著降低快照停机阶段的时延。这一特征为轻量级热点感知机制的设计提供了明确方向，即热点页面的识别不需要全局扫描，只需以低成本捕捉活跃度高度集中的小型核心区域。

\subsection{快速且剧烈的热点漂移}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/py/drift.pdf}
    \caption{典型负载内存写入时空分布}
    \label{fig:drift}
\end{figure}

尽管热点区域的规模相对较小，但其位置并非稳定不变，而是会随着工作负载的阶段性变化而快速漂移。边缘设备上的应用往往具有多阶段的执行流程，例如在计算机视觉场景中，系统会在图像预处理、卷积计算、特征融合和结果输出等不同阶段之间不断切换，从而导致热点页面在极短时间内从某一内存区域跳转至另一区域。如图\ref{fig:drift}所示，在内存热图呈现出显著的阶段性特征：热点区域（深色部分）并非固定不变，而是随着计算图层的推进在地址空间中发生快速迁移，这要求识别机制必须具备极高的响应速度。在 AI 推理和图像处理应用中，这种漂移现象尤为明显：上一时刻频繁写入的区域可能在下一时刻完全冷却，而新的子任务则会迅速产生新的高频写入点。

快速漂移的出现使得依赖长周期窗口统计或简单频度累积的热点推断机制难以发挥作用。传统方法容易出现“滞后性”：当系统完成热点识别并采取相应策略时，热点可能早已发生迁移，从而导致识别失准和带宽浪费。因此，热点识别机制必须具备较高的响应速度，能够捕捉到毫秒级甚至更精细时间尺度上的热点跳变，并在快照不同阶段快速调整优先级，否则无法适应边缘场景中的瞬态写入特征。

\subsection{大幅度的负载波动}

除了空间位置与热点区域的动态变化外，内存脏页产生速率本身也在时间轴上表现出强烈波动。计算类任务（如 TinyLlama 推理和 YOLO 推理）启动时，写入速率会骤然上升，瞬间可能超过底层存储介质的可持续写入带宽；而在系统等待外部事件、传感器输入或网络数据的间歇阶段，脏页产生速率又会降至极低水平，甚至趋近于零。这种“峰谷交替”的写入行为意味着快照系统若采取静态策略，势必在高负载时期面临严重的写入拥塞与重复拷贝，而在低负载时期未能充分利用空闲带宽。

因此，一个高效的热点识别策略必须能够感知当前负载压力，并根据脏页产生速率的实时变化动态调整判断标准。例如，在写入高峰期，更严格的热点过滤能减少冗余写入，避免快照过程与前台业务争抢带宽；而在负载低谷期，系统则可以适当扩大热点识别范围，将更多页面提前处理，从而缩短停机窗口并提高整体吞吐。

\subsection{资源受限环境下的采样悖论}

尽管理论上可以通过频繁采样与复杂统计模型捕捉上述三种特性，但在边缘设备中，由于 CPU 与内存资源有限，难以承受高频的页表扫描、写保护开销或复杂链表维护。更高的采样频率会显著增加计算负载和内存带宽占用，使得监控过程本身成为额外的系统压力来源，甚至可能对前台业务造成干扰。换言之，过于复杂的热点追踪机制会与轻量化、低开销的设计目标直接冲突。

\begin{table}[htbp]
    \centering
    \caption{边缘工作负载内存写入特征与设计启示}
    \label{tab:workload_characteristics}
    \renewcommand{\arraystretch}{1.2}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{l l l l}
        \toprule
        \textbf{核心特征} & \textbf{表现形式} & \textbf{观测规律} & \textbf{设计启示} \\
        \midrule
        \textbf{极度偏斜} & 
        冷热分布不均 & 
        \begin{tabular}[c]{@{}l@{}}Zipf 分布\\少数页承担主要写入\end{tabular} & 
        \textbf{聚焦核心} (无需全量扫描) \\
        \midrule
        \textbf{快速漂移} & 
        热点位置跳变 & 
        \begin{tabular}[c]{@{}l@{}}计算阶段切换\\热点区随时间迁移\end{tabular} & 
        \textbf{敏捷响应} (短周期迭代) \\
        \midrule
        \textbf{负载波动} & 
        写入速率震荡 & 
        \begin{tabular}[c]{@{}l@{}}峰谷交替明显\\瞬间突破存储带宽\end{tabular} & 
        \textbf{动态调节} (自适应阈值) \\
        \bottomrule
    \end{tabular}
\end{table}

因此，边缘虚拟化场景面临一个典型的“采样悖论”：识别热点需要高频采样，但高频采样又在资源受限环境中不可行。这一矛盾迫使我们必须寻求一种新的设计路径，在极低的资源消耗下仍能精准刻写入的局部性特征。表 \ref{tab:workload_characteristics} 总结了本节实验所观测到的边缘虚拟化环境三大核心内存写入特征，以及它们对快照系统设计提出的具体工程启示。



\section{基于硬件辅助脏位的自适应多位老化算法}

针对 \ref{sec:feature} 节中论述的边缘环境下“采样悖论”——即高频热点追踪需求与有限计算资源之间的矛盾，本研究摒弃了传统虚拟化中基于“写保护-异常陷入”（Write Protection \& VM Exit）的重型追踪方案。我们提出了一种轻量级的、软硬协同的自适应多位老化算法。该算法利用现代处理器内存管理单元（MMU）的硬件特性作为低开销传感器，结合极简的位运算逻辑构建状态机，在不中断虚拟机执行流的前提下，实现了对内存页面写入热度的精准量化与分级。

\subsection{传统追踪机制在受限环境下的失效分析}

在详细阐述本研究提出的自适应多位老化算法之前，有必要深入分析传统脏页追踪机制在资源受限环境下的性能瓶颈。以 KVM 为代表的主流虚拟化平台中，常见的内存追踪方法如 Log-Dirty 模式主要依赖页表写保护机制。其基本流程是：Hypervisor 将客户机物理页（GPA）标记为只读，当 Guest OS 尝试写入页面时，会触发扩展页表异常（EPT Violation），导致 VM Exit。CPU 陷入 Host 模式后，Hypervisor 需要保存寄存器状态、刷新 TLB、更新脏页位图，并最终恢复权限，再返回 Guest 执行。

这种机制在服务器级平台上能够提供高精度的写入记录，但在嵌入式边缘虚拟化环境中存在以下两个显著缺陷：

\begin{itemize}
\item \textbf{昂贵的上下文切换开销：}
在嵌入式处理器（如 ARM Cortex-A 系列）中，处理器主频相对较低，流水线较短，乱序执行和缓存容量有限。每次 VM Exit 都需要进行寄存器保存、TLB 刷新、页表状态恢复以及可能的 L1/L2 缓存污染\cite{xu2015vmexit}. 这意味着，当 Guest 执行写密集型任务（如 YOLO 推理、7zip 压缩或其他计算密集型算法）时，频繁的页面写入将引发大量陷入事件，形成所谓的“中断风暴”\cite{liu2011performance}. 这一风暴不仅增加 CPU 的调度压力，而且直接占用执行时间，使业务逻辑的前台计算被迫等待 Hypervisor 处理完成后才能继续执行，从而显著延长快照停机时间，并可能导致前台任务的缓存局部性和流水线连续性受到破坏。换句话说，这种机制在资源受限环境中本身就是性能瓶颈，其代价随写入频率上升呈指数级增长。

\item \textbf{用户态与内核态通信瓶颈：}
在 QEMU/KVM 架构下，用户态的 QEMU 进程需要通过 \texttt{ioctl} 或类似系统调用与内核态同步脏页位图\cite{zhong2016flic}. 每一次同步都涉及内核态与用户态之间的上下文切换和数据拷贝，这在资源受限边缘计算平台上开销极高。当内存写入速率较高时，系统调用频繁出现，可能占据可观的 CPU 周期，导致前台业务计算被迫等待。此外，由于热点页面可能在毫秒级时间尺度上快速漂移，高延迟的位图同步无法及时反映热点变化，使得基于这种同步的脏页追踪策略在边缘场景下难以实现实时性。换句话说，即便追踪机制在逻辑上可行，其实际响应速度也无法满足热点识别所需的高时效性要求。
\end{itemize}

因此，要在边缘设备上实现高效的热点识别，必须切断“写入行为”与“异常中断”之间的强绑定关系，探索一种非侵入式、低开销、可实时捕捉热点的监测手段。这为本文提出的硬件辅助自适应多位老化算法提供了理论基础与设计动机，使得热点追踪能够在保证 Guest 执行连续性的前提下，获得更高的精度与更低的系统开销。

\subsection{硬件辅助的无感监测机制}

为解决传统脏页追踪在边缘设备上的高开销与低响应问题，本研究提出利用处理器硬件提供的脏位特性，构建低开销的无感监测机制。该机制通过软硬协同，将高频异常中断转换为可控的低频轮询过程，从而在不干扰 Guest 执行的前提下，实现对页面写入行为的精准感知。具体设计可以概括为以下几个核心部分：

\begin{itemize}

\item \textbf{硬件脏位作为零开销传感器：}
现代处理器（如 x86 架构的 Accessed Bit，ARMv8.1 架构的 AF Bit）在页表项中维护脏位，当页面被 CPU 写入时，MMU 会自动将脏位置 1 \cite{arm2017v8, intel2015manual}。此过程由硬件流水线完成，无需软件干预，也不会触发 VM Exit 或中断。这意味着脏位本身可以作为一种低成本、零延迟的页面写入传感器，能够捕捉页面在每个时间片内的写入情况，而不会对前台业务造成任何性能干扰。相较于传统写保护机制依赖异常陷入的方法，脏位提供了连续、稳定且可原子读取的写入信息，为后续热度计算奠定了基础 \cite{zhong2016flic}。

\item \textbf{时间驱动的内核扫描策略：}
基于硬件脏位，本研究设计了一个低优先级内核扫描器，周期性遍历虚拟机物理内存对应的页表项。与传统事件驱动的写保护机制不同，扫描器采用固定时间窗口进行轮询，例如每 200ms 扫描一次 \cite{liu2011performance}. 扫描器在读取脏位后立即将其清零，使硬件能够在下一周期重新捕捉页面写入行为。通过这种方式，系统将原本由高频异常触发的写入检测转化为可控的定期采样，不仅避免了“中断风暴”，而且使扫描开销与 Guest 的写入压力解耦，从而在高负载下保持恒定性能。

\item \textbf{连续热度捕捉与状态演化：}
脏位提供了页面在当前时间片内是否被写入的二值信息，但为实现细粒度的热点感知，需要进一步对历史写入行为进行建模。本机制在扫描器层维护页面热度状态，通过位移与衰减操作，将连续周期的写入信息累积到页面热度指标中。这种设计能够将简单的脏位信号转化为连续的热度度量，使系统能够区分瞬时写入与长期高频写入，进而精确区分热点页面与冷页面 \cite{xu2015vmexit}. 连续热度的捕捉机制兼顾了响应速度与历史趋势，适应了边缘负载中热点漂移快速、写入波动剧烈的特征。

\item \textbf{非侵入式执行与系统透明性：}
扫描器和热度更新机制完全运行在 Host 内核态，并以低优先级执行。由于不依赖写保护陷入或异常处理，Guest 的执行路径不会被中断，前台业务的缓存局部性和流水线连续性得以保留 \cite{liu2011performance}。同时，该机制不会引入额外的中断或系统调用开销，确保在负载高峰期的快照操作对业务性能影响最小。这种非侵入式设计为嵌入式边缘虚拟化环境下的实时热点追踪提供了可行方案。

\item \textbf{适应负载波动的动态调节能力：}
边缘场景下，内存脏页产生率在时间轴上呈现强烈波动，高峰期可能瞬间超出存储带宽，而低谷期又会出现空闲带宽 \cite{zhong2016flic}. 基于多位老化状态，系统可以动态调整热点判定阈值或扫描周期，以适应当前负载压力。在高负载阶段，提高热点过滤精度以避免存储拥塞；在低负载阶段，可适当放宽判定标准，将更多页面提前处理，从而充分利用空闲带宽。这种自适应能力保证了热点识别机制在不同业务阶段都能高效工作。

\end{itemize}

\begin{table}[htbp]
    \centering
    \caption{传统写保护机制与硬件辅助脏位机制的性能特性对比}
    \label{tab:mechanism_comparison}
    \renewcommand{\arraystretch}{1.2}
    \setlength{\tabcolsep}{6pt}
    \begin{tabular}{l l l}
        \toprule
        \textbf{对比维度} & \textbf{传统写保护机制 (Traditional)} & \textbf{硬件辅助脏位机制 (Proposed)} \\
        \midrule
        \textbf{触发模式} & 
        事件驱动 & 
        时间驱动 \\
        
        \textbf{核心开销} & 
        \begin{tabular}[c]{@{}l@{}}\textbf{高}（频繁 VM Exit/Entry）\end{tabular} & 
        \begin{tabular}[c]{@{}l@{}}\textbf{低}（周期性内存扫描）\end{tabular} \\
        
        \textbf{业务干扰} & 
        \begin{tabular}[c]{@{}l@{}}干扰CPU流水线\&缓存局部性\end{tabular} & 
        \begin{tabular}[c]{@{}l@{}}非侵入式透明执行\end{tabular} \\
        
        \textbf{边缘适应性} & 
        差 & 
        优 \\
        \bottomrule
    \end{tabular}
\end{table}

这种机制将不可控的高频异常中断转化为可控的低频轮询开销。在 \ref{sec:feature} 节提到的高负载波动场景下，即使前台业务的内存写入速率极高，扫描器的开销依然保持恒定，从而彻底避免了对业务性能的抖动干扰。为后续自适应多位老化算法提供了可靠、连续的写入信息，使得热点页面能够在停机阶段优先处理，并在后台阶段合理调度冷页面，从而最大化降低快照停机时间，同时保证前台业务性能。表 \ref{tab:mechanism_comparison} 对比了传统写保护机制与本研究提出的硬件辅助脏位机制。可以看出，传统方案在资源受限环境下存在严重的“中断风暴”隐患，而新机制通过软硬协同实现了监控过程的低开销与非侵入性。

\section{自适应多位老化热点识别算法}

在资源受限的边缘虚拟化环境中，仅仅依赖单次扫描获取页面的脏位（0 或 1）并不能准确反映页面的长期热度。这是因为单次写入只能告诉我们页面是否被写入过，但无法区分“偶尔写入”的页面和“持续高频写入”的页面。而传统的解决方案，例如 LRU 算法，通常需要维护复杂的链表或队列结构，用于记录页面的写入历史。然而，在内存容量仅有 1GB 到 4GB 的资源受限边缘计算平台上，这类元数据的管理开销过大，不适合实时高效的热点识别。

为了解决这个问题，本研究提出了一种自适应多位老化算法。该算法不需要维护复杂的数据结构，而是利用物理页面的元数据字段，为每个页面分配 8 个比特位（即一个字节）的空间，记为 $S_{page} \in [0, 255]$，就可以在极小的内存占用下模拟页面写入的时间衰减特性。其中，高位表示历史写入状态，用于记录久远周期的写入累积信息，反映页面的时间局部性；低位表示临近周期的写入状态，反映页面的即时活跃度。通过这种表示，每个页面既能记录最近的写入情况，也能保留历史写入信息，从而实现轻量化的热度追踪。不同于传统的固定窗口算法，本算法引入了动态位宽变量 $N$（$2 \le N \le 8$）。虽然每个页面拥有 8 位存储空间，但在实际运行时，系统会根据当前负载的热点分布情况，动态调整有效使用的位数 $N$。这意味着算法可以在“短历史”与“长历史”之间灵活切换，以适应不同的工作负载特征。

在每个扫描周期结束时，算法对每个页面执行状态更新。状态更新的逻辑可以用如下公式表示：
$$S_{\mathrm{new}} = \bigl( (S_{\mathrm{old}} \ll 1) \mathbin{|} H_{\mathrm{bit}} \bigr) \mathbin{\&} M_{N}$$
。其中，$S_{\mathrm{old}}$ 为页面上一周期的状态，$H_{\mathrm{bit}}$ 为从 PTE 读取的硬件脏位（1 表示被写入，0 表示未写入），$M_{N} = 2^N - 1$ 为当前有效位宽 $N$ 对应的掩码（例如 $N=3$ 时掩码为 $00000111_2$）。该算法包含三个关键步骤：

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/aging.png}
    \caption{自适应多位老化热点识别算法}
    \label{fig:aging}
\end{figure}

\textbf{（1）老化（Aging）}：算法利用位运算模拟时间衰减与新信息的注入。首先，通过左移操作 $(S_{\mathrm{old}} \ll 1)$，将页面历史的写入记录向高位推移，这代表了时间的流逝；随后，通过位或操作 $\mid H_{\mathrm{bit}}$，将本周期最新的硬件写入状态 $H_{\mathrm{bit}}$ 填充到最低位（LSB）。最后，利用掩码 $M_{N}$ 进行截断，仅保留最近 $N$ 个周期的状态。这一过程构建了一个长度为 $N$ 的滑动窗口，数值 $S_{page}$ 的大小直接量化了页面在当前时间窗口内的活跃密度。

\textbf{（2）更新（Update）}：这是本算法的核心机制。由于不同应用负载的局部性特征差异巨大，固定的监测窗口长度往往难以奏效：窗口过短容易导致误判（将偶发写入视为热点），窗口过长则反应迟钝。为此，算法引入了负反馈调节机制。
系统在每个周期统计被判定为“极热页面”的比例 $R_{hot}$，并据此调整 $N$ 值：
\begin{itemize}
\item \textbf{增加难度（$N \uparrow$）}：当 $R_{hot} > 5\%$ 时，意味着当前的热点判定标准过于宽松，导致系统中出现了过多的“热点”，这将给后续的快照传输带来巨大压力。此时，系统将 $N$ 增加 1 位（上限为 8），拉长监测周期，要求页面在更长的时间跨度内保持活跃才能被视为热点，从而过滤掉伪热点。
\item \textbf{降低难度（$N \downarrow$）}：当 $R_{hot} < 0.1\%$ 时，意味着判定标准过高，系统难以捕捉到有效的热点信息。此时，系统将 $N$ 减少 1 位（下限为 2），降低识别门槛，以便更敏锐地锁定潜在的活跃页面。
\end{itemize}
通过这种动态调节，算法能够始终将热点页面的比例控制在 0.1\%-5\% 的合理区间，确保系统资源聚焦于真正的瓶颈区域。

\textbf{（3）迭代（Iteration）}：经过老化和更新两步操作后，新的状态 $S_{\mathrm{new}}$ 包含了一个关于页面写入历史的长度为 $N$ 的滑动窗口记录。新状态 $S_{\mathrm{new}}$ 将在下一监测周期替代 $S_{\mathrm{old}}$ 参与计算。通过周期性的迭代，状态 $S$ 能够以 $2^N$ 种组合（范围从 $0$ 到 $2^N-1$）精确表征页面的写入频率与写入新鲜度之间的关系。状态 $S_{\mathrm{new}}$ 的值越高（例如趋近于 $2^N-1$），表明该页面在近期和历史 $N$ 个周期内都保持了极高的活跃度，即其写入热度高。反之，若状态值持续处于低位（例如 $0$），则表明该页面处于冷寂状态。这种机制在保留极小内存开销（仅利用页表项预留的 8 bit 空间）的同时，实现了对内存页写入热度的可变粒度量化与实时追踪。

图\ref{fig:aging}详细展示了该算法的状态流转逻辑：页面状态在 $[0, 2^N-1]$ 之间跃迁，硬件脏位（H\_bit）决定了状态演化的数值方向，而动态位宽 $N$ 决定了状态空间的范围。系统据此将页面精准映射为冷寂（0）、温热（中间值）与极热（全 1）三类，分别对应不同的快照处理策略。并且，系统会根据极热页面的占比反馈，动态增加 or 减少 $N$ 的值，以维持分类的有效性。

这种位运算逻辑依然极其简单，在 ARM 处理器上仅需数个指令周期即可完成，且不需要分配额外的内存对象，非常适合资源受限环境。通过自适应多位老化算法，每个页面的状态可以映射为三种热度等级，这些等级可以直接指导快照系统采取差异化的处理策略，从而实现对热点页面的精确调度。具体而言：
\begin{itemize}\item 
    \textbf{极热页面（State = $2^N - 1$）}：表示该页面在最近 $N$ 个扫描周期内每次均被写入，属于持续高频写入的页面。算法通过动态调节 $N$（当热点过多时增加 $N$，过少时减少 $N$），将这类页面的比例维持在总内存的 0.1\%-5\% 之间。这类页面承担了绝大部分写入操作，如果在预拷贝阶段就尝试传输，很可能传输完成后页面已经再次被修改，导致重复写入和带宽浪费。因此，对于极热页面，快照系统会选择在停机阶段一次性保存，或者配合写合并机制在内存中暂存，最大程度减少无效 I/O。
    
    \item \textbf{温热页面（$0 < \text{State} < 2^N - 1$）}：表示最近 $N$ 个周期内页面有被写入记录，但未达到持续活跃的程度。这包括了刚刚从冷状态变热的迁入期页面，或曾经是热点但正在冷却的页面。这类页面状态不稳定，快照系统需要特别关注。在快照过程中，这类页面会启用写时复制（COW）机制，一旦发生写入就立即捕获副本，以防止数据丢失或不一致。
    
    \item \textbf{冷寂页面（State = 0）}：表示连续 $N$ 个周期内页面未被写入，这类页面占据了绝大部分内存（通常超过 80\%），例如代码段、只读数据区等。由于其写入极少，数据高度稳定，快照系统可以将其标记为安全区域，在后台阶段低优先级传输。由于这些页面几乎不会被修改，后台传输过程中几乎无需重传脏页，从而显著节约 I/O 带宽。\end{itemize}通过自适应多位老化状态机，系统将复杂的内存写入模式（包括 Zipf 分布的热点、快速漂移和负载波动）映射为三种可操作的状态，实现了“写入频率量化 + 热度分级 + 快照策略映射”的闭环。相比固定长度的检测方法，该机制通过动态调整监测窗口长度 $N$，能够更灵活地适应不同负载特征，将计算和 I/O 资源更精准地集中在关键页面上，从而在降低快照停机时间的同时，最大程度保证前台业务性能。

\section{两阶段工作集感知策略}

虽然自适应多位老化算法能够有效地对内存页面进行热度分类，但在快照启动初期，由于历史写入信息尚不足，仅依赖单周期采样往往无法捕获全部潜在的热点页面。这可能导致预拷贝阶段的迭代收敛缓慢，增加脏页重传次数，降低快照效率。针对这一问题，本研究引入了两阶段工作集感知策略：根据信息积累程度动态调整热点判定的激进程度，从而在快照前期加快工作集收敛。

\textbf{阶段1：基于局部性的激进预测}

在快照启动的初始几个监测周期内，系统对内存写入模式的了解仍非常有限。为了防止潜在热点遗漏导致后续迭代产生大量脏页，本阶段采用“宁滥勿缺”的激进策略，充分利用内存的空间局部性原理。当检测到某页面 $P_i$ 的脏位为 1 时，不仅将 $P_i$ 标记为热点，还将其物理地址相邻的页面 $P_{i-1}$ 与 $P_{i+1}$ 视为潜在热点。
这一策略的依据在于，在数组处理、矩阵运算或连续数据块写入的场景中，相邻页面极有可能被短时间内连续写入。通过激进捕捉，可以快速覆盖潜在工作集，避免热点遗漏并减少预拷贝初期迭代次数。

\textbf{阶段2：精确追踪}

随着监测周期的推进，系统已经积累了足够的写入信息，能够对页面热度做出初步判断。如果继续将邻近页面作为潜在热点，会导致热点集合虚高，增加无效传输。因此，系统会自动切换至精确追踪模式。在该模式下，仅对实际检测到硬件脏位为 1 的页面执行热度累加。此模式取消了邻近页面的模糊推测，确保热点集合更加精确。系统在完成一次全内存扫描（即一轮预拷贝迭代）后，由阶段1自动切换至阶段2，使热点识别过程逐步收敛。

\section{高效内核态实现与优化}

为了确保前述自适应多位老化算法及两阶段工作集感知策略在资源受限边缘计算平台上的高效执行，本研究在实现层面进行了深度优化，构建了一套高性能的内核态与用户态交互机制，从而最大限度地降低 CPU 开销和内存访问延迟。

\subsection{共享内存热度位图}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/share.png}
    \caption{共享内存热度位图机制}
    \label{fig:share}
\end{figure}

在标准的 KVM 虚拟化架构中，用户态 QEMU 进程获取虚拟机脏页信息通常依赖于 \texttt{ioctl(KVM\_GET\_DIRTY\_LOG)} 系统调用 \cite{kivity2007kvm}. 然而，在高频扫描场景下，频繁的系统调用会带来显著的上下文切换开销，严重影响前台业务性能。

为此，本研究在 KVM 内核模块中对 \texttt{kvm\_memory\_slot} 结构进行了扩展，增加了一个热度位图。通过 Linux 的 \texttt{mmap} 机制，将这块内核物理内存直接映射到 QEMU 用户态虚拟地址空间，实现了内核与用户态的共享访问 \cite{liu2011performance}。

如图\ref{fig:share}所示, 在这一设计中，内核态职责是扫描线程周期性遍历页表，读取硬件脏位，并直接在热度位图上更新页面状态。用户态职责是快照决策线程无需通过系统调用获取脏页信息，而是直接读取映射的共享内存区域，获取最新的页面热度分布，用于动态调整预拷贝和停机阶段的传输策略。该机制完全消除了数据拷贝和高频系统调用，实现了零拷贝（Zero-Copy）的数据传递方式，从而显著提升了热点识别与快照决策的执行效率 \cite{xu2015vmexit}.

\subsection{无锁并发控制}

由于内核扫描线程（生产者）与用户态决策线程（消费者）同时运行，必须保证对热度位图的访问一致性。为了避免传统锁机制导致的 CPU 流水线停顿和性能下降，本研究采用无锁编程技术，实现高效并发控制：

\begin{itemize}
    \item \textbf{原子操作}：内核线程在更新热度位图状态时，使用原子指令确保状态位的读-改-写过程不可分割，避免竞争条件。
    \item \textbf{RCU 机制}：利用 Linux 内核的 RCU（Read-Copy-Update）机制保护内存槽元数据，在热度位图扩容或销毁时保证并发安全，同时允许用户态线程在无需阻塞的情况下读取数据。
\end{itemize}

通过共享内存与无锁同步的结合，本研究实现了高频访问热度采集与快照策略决策的并行化，使自适应多位老化算法在资源受限的嵌入式边缘虚拟化环境下能够以最小的性能开销运行，同时保证数据一致性和实时性。

\section{本章小结}

本章针对资源受限环境下虚拟化快照面临的“采样悖论”与热点漂移挑战，提出了一套软硬协同的轻量级热点识别机制。
首先，通过对典型边缘工作负载的深入分析，揭示了内存写入呈现出的显著 Zipf 分布与时空局部性特征，明确了以极低开销锁定核心工作集的可行性。
其次，本章摒弃了高昂的写保护追踪方案，创新性地设计了基于硬件辅助脏位的自适应多位老化热点识别算法。在不中断虚拟机运行的前提下，模拟了时间维度的热度衰减，成功将页面划分为极热、温热与冷寂三个层级，为快照策略的差异化调度提供了精准依据 。
再次，为了克服热点识别初期的滞后性，引入了两阶段工作集感知策略，通过从激进的空间邻近推测到精确追踪的动态切换，确保了预拷贝阶段脏页集合的快速收敛 。
最后，在系统实现层面，通过内核共享内存与无锁同步机制，实现了用户态与内核态的零拷贝交互，显著降低了监控过程的系统损耗 。本章的研究成果为后续章节构建基于资源反馈的动态快照决策模型提供了实时、可靠的数据支撑。

