%!TEX root = ../main.tex

\chapter{基于热度感知和资源反馈的动态快照策略}
\label{ch:strategy}

在第四章中，本研究构建了基于硬件脏位与自适应多位老化算法的轻量级内存热点感知机制，成功实现了对虚拟机内存写入时空局部性的低开销追踪与冷热分级。在此关键基础上，本章将围绕 HPRO 系统的策略决策层展开，实现快照任务的自适应调度与资源优化。本章首先阐述基于热度感知的分级传输策略，界定冷热页面的差异化处理流程；其次，建立系统压力指数（SPI）的定量计算模型，为决策提供实时、多维的量化依据；最后，构建基于 SPI 闭环反馈的自适应快照状态机，实现快照执行模式在不同系统负载下的智能切换，确保在边缘资源受限环境下快照任务的稳定与高效执行。

\section{基于热度感知的分级传输策略}

传统快照机制在虚拟化系统中长期面临着“难以收敛的在线传输过程”与“过长的恢复时延”之间的性能博弈问题。具体而言，典型的 Pre-copy 机制需要在虚拟机持续运行的情况下反复检测并传输脏页；当应用负载呈现高频写入特征时，大量脏页会在各轮迭代中重复出现并被迫多次重传，使得迭代往往难以在可控时间内完成收敛，最终导致无法预测的长时间停机。而 Post-copy 机制虽然可以迅速完成迁移或快照启动，但其后续依赖的按需页拉取会引发密集的缺页中断，严重拖慢业务执行效率，对系统的瞬时响应能力造成显著扰动。

基于上述瓶颈，本研究提出了一种“基于热度感知的分级传输策略”。该策略的核心理念在于彻底摆脱传统快照对内存空间的线性、均匀、无差别扫掠，转而将第四章中构建的页面热度状态 ($S_{\text{page}}$) 深度嵌入快照全流程，通过构建从“页面热度特征”到“传输时序策略”的精确映射，将快照过程从传统的“全量扫描 + 多轮迭代”重塑为“识别驱动 + 分级决策”的结构化执行模型。

\begin{figure}[htbp] 
    \centering 
    \includegraphics[width=0.6\linewidth]{figures/hotcopy.png} 
    \caption{基于热度感知的分级传输策略} 
    \label{fig:hotcopy} 
\end{figure}

如图 \ref{fig:hotcopy} 所示，整个分级策略由三个彼此衔接紧密的阶段构成：首先在“热度感知预拷贝”阶段，系统不再追求脏页数量的下降，而是以热度模型的收敛为唯一目标，快速构建高精度的内存热度画像；随后进入“最小化的停止并拷贝阶段”，系统利用短暂的静止窗口对极热页面进行原子化集中传输，通过牺牲极小的停机时间换取对核心高风险数据的一致性保证；最后在虚拟机恢复运行后的“差异化后拷贝阶段”，系统依照温热页与冷寂页的预测风险进行分级调度，实现了整体传输过程对前台业务可感知度的显著降低。与传统机制相比，该策略有效避免了无效迭代、脏页震荡以及缺页风暴等典型性能陷阱，使得 HPRO 系统能够在资源受限环境下仍维持稳定、可预测的快照性能。


\textbf{阶段一：以热度感知为核心目标的预拷贝}

整个快照流程始于“热度感知预拷贝”阶段。本阶段的设计理念与传统 Pre-copy 完全不同：传统机制将“减少脏页率”作为阶段切换条件，因此在高写入负载下往往会陷入传输—变脏—重传的循环；而在本研究提出的方案中，系统将控制逻辑从“追求数据传输量的下降”转向“追求热度识别特征的稳定收敛”。

在执行初始内存扫描时，系统同时运行自适应多位老化算法，对页面访问频率、写入行为以及时间局部性进行综合建模。此时的数据传输并非任务主线，而是模型识别的辅助动作。系统持续监测热度模型的置信度，并以此作为判断阶段切换的唯一依据。当极热页、温热页与冷寂页的分类稳定、模型收敛后，无论当前已经传输了多少数据，也无论脏页率是否下降，系统都将立即终止预拷贝过程。

这种“识别优先”的设计策略带来三方面收益：（1）大幅缩短了预拷贝窗口，避免带宽资源被消耗在低效的迭代传输中；（2）使系统在真正关键的数据分流之前就具备了精准画像，为后续的停机决策与时序调度奠定基础；（3）将动态迭代的不确定性削减到最小，使快照性能更具可预测性。这一阶段的完成标志着快照流程从“全量均质传输”正式转向“基于认知驱动的结构化传输”。

\textbf{阶段二：最小化的停止并拷贝}

随着热度画像的生成，系统进入停机阶段（Stop-Phase）。在此阶段，vCPU 被短暂暂停，整个内存状态处于严格的静止状态。本策略的核心创新在于：将所有识别为“极热”的页面（其占比通常仅为总内存的 0.1\%–5\%）统一推迟至该阶段进行集中传输。

极热页是导致传统 Pre-copy 缓慢甚至不收敛的根源，它们在业务运行期间具有极高的写入频率，使任何“在线”传输均不可避免地遭遇重新变脏，从而导致反复重传。通过将其从在线阶段剥离并置于停机窗口集中处理，系统将动态、失控的重传行为转化为一个短暂且完全确定的原子化操作，从根本上切断了脏页震荡的传播链路。

同时，由于极热页数量占比极低且页面尺寸固定，集中写入可以在毫秒级内完成，从而大幅压缩传统 Stop-and-Copy 阶段的时长。在此静止窗口完成极热页的写入不仅进一步提高了快照数据的一致性，还避免了在 VMExit 或硬中断中处理这些页面所带来的高昂开销，实现了快照系统的高确定性和高可控性。

\textbf{阶段三：温热优先的差异化后拷贝}

在极热页完成原子化写入后，虚拟机立即恢复运行，系统进入最后的“差异化后拷贝”阶段。此时剩余的未持久化页面包括温热页与冷寂页，它们在业务恢复后并不会立刻对一致性造成威胁，但却会对恢复后的业务性能带来不同程度的干扰。

温热页是具有潜在写入活动的高风险页面，如果不提前传输，其写入操作会在恢复阶段触发写保护异常，引发 VMExit、EPT 修改等开销，拉高业务处理延迟。因此，本策略将温热页置于后拷贝队列的首位，优先以异步方式传输。通过抢先完成这些页面的数据落盘与页表保护解除，系统能够在业务即将访问时提前消除潜在的性能陷阱，从而以一种“竞态规避”的方式保护业务连续性。

相比之下，冷寂页的访问概率极低，对业务影响最小。系统采用低优先级后台线程在空闲带宽下进行从容传输，使其不会干扰业务负载峰值。这种分级时序的设计不仅实现了数据最终一致性，还最大程度减轻了快照过程对业务性能的侵扰，实现了“快照可感知性最小化”的设计目标。

\section{系统压力指数（SPI）建模}

在第四章中，我们通过轻量级热点识别机制解决了“保存什么”的问题，即优先锁定并处理高频修改的核心工作集；在第5.1节中，我们通过基于热度感知的级传输策略解决了“怎么保存”的问题。然而，在资源受限且负载波动剧烈的嵌入式环境中，仅解决数据识别和保存问题是不够的。“何时保存”以及“以何种速率保存”同样决定了系统的最终可用性。

传统的快照机制通常采用静态的执行参数，例如固定的迭代次数、预设的传输带宽限制或恒定的脏页阈值。这种静态策略无法适应边缘设备瞬息万变的资源状态：在系统空闲时，静态限制导致带宽浪费，延长了快照时间；而在业务高峰期，强制的快照操作又会与前台任务激烈争抢 CPU 与 I/O 资源，导致服务质量（QoS）违约。

为了解决上述矛盾，本节提出了一种基于SPI的动态反馈控制模型。该模型将底层的异构资源状态抽象为统一的量化指标，并据此驱动快照引擎在“业务优先”与“快照优先”等多种模式间自适应切换，同时结合动态批处理机制优化连续快照的 I/O 路径，从而在保证数据一致性的前提下，实现资源利用效率与业务性能的最优平衡。为了实现对快照执行过程的自适应调度，首要任务是在资源受限的边缘环境中建立一个能够全面、准确反映当前设备综合负载状况的数学模型。嵌入式环境的资源约束具有显著的多维度耦合特性，因此，单一的 \text{CPU} 使用率或内存水位无法完整且精确地刻画系统的瞬时“繁忙程度”，容易导致决策失误。为此，本研究定义了SPI，这是一个归一化数值 $\text{SPI} \in [0, 1]$，其数值高低直接反映了系统资源竞争的烈度，为策略决策层提供了统一的量化反馈信号。

\subsection{多维资源融合计算模型}

\text{SPI} 的构建采用了多维资源融合计算模型，综合了计算、存储 \text{I/O}、内存以及能源四个关键维度的实时状态。这种多变量聚合机制确保了对边缘设备复杂约束条件的全面考量。其数学表达式定义如下：

$$
\text{SPI} = \alpha \cdot \mathcal{N}(L_{\text{cpu}}) + \beta \cdot \mathcal{N}(D_{\text{io}}) + \gamma \cdot (1 - \mathcal{N}(M_{\text{free}})) + \epsilon \cdot (1 - \mathcal{N}(E_{\text{bat}}))
$$

公式中各项参数的机制原理和作用如下：

$L_{\text{cpu}}$：表示 \text{CPU} 平均负载（Load Average）或实时利用率，用于衡量计算资源的瞬时竞争压力。

$D_{\text{io}}$：表示块设备的 \text{I/O} 等待队列深度（Queue Depth）或平均等待时间（await）。该指标是衡量 \text{Flash} 存储拥塞程度和 $B_{\text{io}}$ 约束紧张程度的关键指标，其数值的增长直接预示着潜在的 \text{I/O} 阻塞风险。

$M_{\text{free}}$：表示系统当前的剩余可用物理内存页面数。采用 $1 - \mathcal{N}(M_{\text{free}})$ 形式，确保在内存剩余量低时，该分量对 \text{SPI} 的贡献值增大，体现了内存匮乏的压力。

$E_{\text{bat}}$：表示电池剩余电量百分比。对于依赖电池供电的移动边缘设备，能源效率至关重要。电量越低，策略对能耗的敏感度越高，故同样采用反向映射 $1 - \mathcal{N}(E_{\text{bat}})$。

$\mathcal{N}(\cdot)$：归一化函数。鉴于各物理量（如 $L_{\text{cpu}}$ 的百分比、$D_{\text{io}}$ 的毫秒级时间）的量纲和数值范围存在显著差异，所有原始指标必须通过映射函数 $\mathcal{N}: [0, X_{\max}] \to [0, 1]$ 进行线性或非线性归一化，以消除量纲差异，确保加权聚合的有效性。

$\alpha, \beta, \gamma, \epsilon$：权重系数。这些系数反映了各资源维度在特定应用场景下的相对重要性，且必须满足 $\alpha + \beta + \gamma + \epsilon = 1$ 的约束条件。权重的设定并非固定不变，而是根据具体的边缘应用需求进行预配置。例如，在计算密集型的 \text{AI} 推理场景中，$\alpha$（\text{CPU} 权重）将占据主导地位，而在数据采集等 \text{I/O} 密集型场景中，$\beta$（\text{I/O} 权重）则应被赋予更大权重，体现出策略设计的可定制性。

\subsection{迟滞比较与防震荡设计}

由于实际的系统负载通常具有显著的瞬时波动性（例如突发的中断处理或短暂的进程切换），如果策略决策层直接使用瞬时 \text{SPI} 值作为状态切换的依据，可能会导致系统在不同的执行模式之间频繁跳变，即发生策略震荡（Thrashing）。这种频繁的切换不仅会引入额外的管理开销和模式切换延迟，更会消耗 $C_{\text{total}}$ 资源，破坏系统的稳定性。

为此，本研究在决策逻辑中引入了源自控制理论的迟滞比较器（Hysteresis Comparator）机制。该机制通过设置高低两个分离的阈值 $T_{\text{high}}$ 和 $T_{\text{low}}$，在状态切换路径中增加了惰性（Inertia），从而有效平滑了短期的负载毛刺。具体切换条件定义如下：

系统仅当 $\text{SPI}$ 持续超过高阈值与安全边际之和 $T_{\text{high}} + \Delta$ 时，才升级至更高压力的应对模式。

系统仅当 $\text{SPI}$ 持续低于低阈值与安全边际之差 $T_{\text{low}} - \Delta$ 时，才降级至更宽松的模式。

其中 $\Delta$ 为策略的安全边际。这种设计相当于在决策环路中内置了一个低通滤波器，成功地排除了系统负载的瞬时噪声干扰，确保了策略切换的稳定性和可靠性，避免了不必要的资源管理开销。

\section{基于 \text{SPI} 反馈的快照自适应模式切换机制}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/spi.png}
    \caption{基于 \text{SPI} 反馈的快照自适应模式切换机制}
    \label{fig:spi}
\end{figure}


基于实时计算的 \text{SPI} 值，\text{HPRO} 系统设计了一个三级自适应快照状态机，用于自动在高压模式、标准模式和低压模式之间进行平滑切换。图\ref{fig:spi}展示了该三级状态机的流转逻辑：系统引入迟滞比较机制，仅当SPI突破高阈值（$T_{high}$）或跌破低阈值（$T_{low}$）时才触发模式变更，有效防止了因负载瞬时波动导致的策略震荡。该状态机是策略决策层的核心控制逻辑，其职能是将连续的 \text{SPI} 值转化为离散、可执行的快照模式，从而实现对资源 $C_{\text{total}}$ 和 $B_{\text{io}}$ 的精细化控制。每种模式对应一套经过优化的热点判定阈值、后台传输策略和流控参数，以确保快照执行的适应性与稳定性。

\subsection{高压模式：业务性能优先与最小化干扰}

当 $\text{SPI}$ 超过预设的高阈值（例如 $0.8$）时，表明系统正处于极度繁忙或资源临界状态，此时 $C_{\text{total}}$ 或 $B_{\text{io}}$ 之一或两者均面临高竞争。在此紧急情况下，快照操作被定义为潜在干扰源，系统将立即进入高压模式，并采取“最小化干扰”策略，以确保核心实时业务的优先级不受侵犯。

在快照进入高压阶段时，策略决策层首先大幅提高第四章所述自适应多位老化算法的判定阈值，使得只有拥有最高活跃度和最新写入记录的“极热页”才会被纳入最终的停机保存集合。通过这种更为严格的筛选逻辑，系统将需要在停机窗口中处理的数据量 \(M_{\text{stop}}\) 压缩至理论最小，从而显著缩短停机时延 \(D_{\text{stop}}\)，以最大限度降低对实时业务的扰动。在此基础上，策略层进一步指令执行优化模块暂停或以极低速运行后台脏页扫描线程与数据传输线程，通过主动释放被占用的 CPU 流水线与总线带宽，避免快照流程在高负载环境下与业务进程争抢 \(C_{\text{total}}\) 资源。此时内存一致性的维护完全依赖被动触发的写时复制（COW）机制，从而在接受未来缺页概率略有上升的前提下，实现当前运行稳定性与业务性能影响最小化之间的最优平衡。


\subsection{低压模式：资源利用最大化与激进拷贝}

当 $\text{SPI}$ 持续低于预设的低阈值（例如 $0.3$）时，表明系统资源充裕，存在大量的空闲 $C_{\text{total}}$ 和 $B_{\text{io}}$。此时应采取激进策略，目标是以资源和带宽的消耗换取快照的快速完成，并主动减少未来的潜在开销。系统进入低压模式，执行激进拷贝：

在系统负载处于空闲阶段时，策略层会主动降低热点判定门槛，将更多的“温热页”纳入停止并拷贝范围。由于此时 CPU 与 I/O 资源均较为充裕，加速预拷贝不会对用户体验造成负面影响；相反，通过提前加载更多非核心但潜在活跃的数据，系统实现了对未来资源竞争风险的前置防御，显著降低了运行阶段因负载上升而可能触发的缺页中断概率，从而减少未来在 \(C_{\text{total}}\) 上的异常处理开销。在扩大保存范围的同时，策略层同步解除后台传输线程的带宽限制，指示执行优化层以全速利用所有可用的 \(B_{\text{io}}\) 通道，将剩余内存数据快速刷写至 Flash。该设计最大化了系统资源的瞬时利用率，显著缩短了快照的整体持续时间，并尽早释放快照占用的内存与 I/O 锁，使系统能够迅速回到零快照负载的运行状态。


\subsection{标准模式：动态平衡与均衡调度}

当 $\text{SPI}$ 处于中间区间（例如 $0.3-0.8$）时，系统采用标准模式。此时系统资源供需处于动态平衡状态，策略的目标是保证快照稳定推进的同时不影响前台业务的正常运行，寻求效率与稳定性的帕累托均衡。在此模式下：

在进入稳定执行阶段后，系统会启动基于令牌桶的 I/O 流控机制，策略层根据 SPI 的实时微小波动动态调整令牌桶速率参数，对快照写入流 \(b_{\text{snap}}\) 进行细粒度调控，确保快照 I/O 始终处于安全带宽阈值之内，从而在不饿死业务 I/O 的前提下平稳推进冷页面的后台传输。同时，热点判定标准维持默认配置，系统持续监控内存写入状态并保持对页面活跃度变化的敏感捕获。该模式构成快照生命周期中持续时间最长、影响最终快照时间最关键的执行阶段，其流控稳定性与监控精度直接决定了快照过程的整体吞吐与业务透明性。


\section{基于 SPI 的连续快照动态增量策略}
\label{sec:cont}
在边缘计算场景中，为了保障关键业务（如工业控制数据日志、数据库事务）的数据安全性和可追溯性，系统往往需要提供时间点恢复（Point-in-Time Recovery, PITR）能力。这要求虚拟化平台能够以极高的频率（例如每数秒甚至亚秒级）执行连续快照。连续快照的核心挑战在于如何高效地处理两次快照检查点之间产生的“增量脏页”。在资源受限的嵌入式设备上，高频的增量数据落盘会与前台业务激烈争抢有限的系统总线与 \text{I/O} 带宽。本节首先分析传统增量策略在调度层面的局限性，进而提出基于 \text{SPI} 反馈的动态批处理策略，旨在实现 \text{I/O} 吞吐开销与数据保护窗口（Recovery Point Objective, RPO）的自适应平衡。

\subsection{传统增量机制的调度困境与机制失效}

现有的连续快照技术主要沿用数据中心服务器的两种极端策略：同步的写时复制（COW）与异步的懒惰写入。然而，在边缘异构环境下，这两种策略在资源调度层面均暴露出严重的不适应性，导致系统性能和数据安全性的权衡失败。

\subsubsection{写时复制}

写时复制策略追求极致的数据实时性：一旦虚拟机尝试修改页面，\text{Hypervisor} 立即拦截并触发 \text{I/O} 将旧数据写入持久化存储。然而，在写密集型负载（如高性能数据压缩或 \text{AI} 模型权重更新）下，内存修改极其频繁。COW 机制会将连续的逻辑内存写入打散为海量的、4\text{KB} 粒度的高频 \text{I/O} 请求。这种调度困境在于，每一次 \text{I/O} 请求都会触发内核中断处理、昂贵的上下文切换以及存储协议栈的开销。在单核性能较弱、微架构流水线较浅的嵌入式处理器上，这种密集的“中断高发态势”会严重抢占业务逻辑的 \text{CPU} 时间片，导致前台业务出现显著的性能抖动，直接违反了 \text{3.1} 节提出的计算资源竞争约束。 \text{CPU} 大部分时间被消耗在模式切换和 \text{I/O} 提交上，而非业务计算，导致了计算资源的无效损耗。

\subsubsection{懒惰写入}

懒惰写入策略将增量脏页全部暂存在内存缓冲区中，直到下一个快照周期点（例如 $30$ 秒后）才统一执行批量落盘。虽然这种方法通过聚合减少了 \text{I/O} 提交的次数，但它将压力过度转移到了内存子系统。边缘设备内存容量通常仅为 $1\text{GB}-4\text{GB}$，在长周期的快照间隔内，积压的脏页可能迅速耗尽可用物理内存，触发 \text{OOM}（Out-of-Memory）机制甚至导致虚拟机崩溃，从而违反了内存约束 $M_{\text{total}}$。更关键的是，这种策略显著扩大了数据丢失风险窗口。一旦设备在快照间隔期内发生断电或硬件故障，所有暂存在内存中的增量数据将全部丢失，使得系统的 \text{RPO}（即数据丢失的最大容忍时间）被拉长到秒级甚至数十秒，无法满足高可靠性场景对 \text{RPO} 的严格要求。因此，该策略牺牲了数据安全性以换取 \text{I/O} 效率，在安全性要求高的边缘环境中是不可接受的。

\begin{table}[htbp]
    \centering
    \caption{传统连续快照增量策略在边缘环境下的缺陷对比}
    \label{tab:traditional_defects}
    \renewcommand{\arraystretch}{1.2}
    \setlength{\tabcolsep}{6pt}
    \begin{tabular}{l l l l}
        \toprule
        \textbf{策略名称} & \textbf{调度逻辑} & \textbf{关键性能瓶颈} & \textbf{边缘环境失效原因} \\
        \midrule
        \textbf{写时复制} & 
        \begin{tabular}[c]{@{}l@{}}实时拦截\\单页立即落盘\end{tabular} & 
        \begin{tabular}[c]{@{}l@{}}\textbf{CPU 中断密集}\\上下文切换开销大\end{tabular} & 
        \begin{tabular}[c]{@{}l@{}}抢占业务时间片\\引发性能抖动\end{tabular} \\
        
        \midrule
        \textbf{懒惰写入} & 
        \begin{tabular}[c]{@{}l@{}}周期性聚合\\批量延迟落盘\end{tabular} & 
        \begin{tabular}[c]{@{}l@{}}\textbf{内存占用过高}\\数据丢失窗口长\end{tabular} & 
        \begin{tabular}[c]{@{}l@{}}触发 OOM 崩溃\\无法满足 RPO\end{tabular} \\
        \bottomrule
    \end{tabular}
\end{table}

表 \ref{tab:traditional_defects} 对比了上述两种传统增量策略在资源调度层面的核心差异。可以看出，无论采取极端的实时策略还是懒惰策略，均会在异构资源受限的边缘节点上触发严重的性能瓶颈或可靠性风险，无法满足连续快照的需求。

\subsection{基于 \text{SPI} 的动态增量批处理策略}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/cont.png}
    \caption{基于 \text{SPI} 的动态增量批处理策略}
    \label{fig:cont}
\end{figure}

为了调和上述“实时性”与“系统开销”之间的内在矛盾，本研究提出了一种动态增量批处理策略。该策略的核心思想是引入一个弹性伸缩的“增量缓冲区”，并利用前文定义的 SPI 作为反馈信号，动态调节数据的聚合粒度（Batch Size，下文统一称为批大小）。系统不再僵化地执行“立即写”或“最后写”，而是根据当前的系统负载压力，在两者之间寻找动态平衡点，将批大小定义为关键的自适应控制变量。如图\ref{fig:cont}所示，该模型构建了批大小与SPI的正相关反馈：在低负载区，批大小收敛至4KB以保障数据鲜度；在高负载区，批大小指数级增长以减少IOPS中断，实现‘积少成多’的削峰效果。

\subsubsection{高负载抗抖动：聚合写模式}

当系统 \text{SPI} 指数较高（$\text{SPI} > 0.6$），表明当前 \text{CPU} 算力或 \text{I/O} 带宽已接近饱和。此时，策略倾向于增大 批大小，例如从默认的 $4\text{KB}$ 逐步倍增至 $64\text{KB}$、 $128\text{KB}$ 甚至更大，以容忍更多的脏页在内存中短暂停留。这种调度优化通过将多个离散的逻辑页面合并为一次大的物理写入请求，大幅减少了 \text{I/O} 系统调用的次数（IOPS）。从机制上讲，它降低了 \text{CPU} 处理 \text{I/O} 中断的频率，通过这种主动让渡总线控制权的行为，快照线程减轻了对前台高优先级业务的干扰，有效地起到了负载“削峰填谷”的作用，缓解了高负载下的 \text{CPU} 竞争，保障了计算资源的稳定性。

\subsubsection{低负载强实时：低延迟模式}

当系统 \text{SPI} 指数较低（$\text{SPI} < 0.3$），表明当前系统资源相对充裕，存在闲置的 $C_{\text{total}}$ 和 $B_{\text{io}}$。此时，策略倾向于减小 批大小，甚至退化为单页（$4\text{KB}$）模式。在资源允许的情况下，系统利用闲置带宽加速数据的持久化，一旦有数据修改，立即或以极小的批次落盘。这确保了持久化存储中的镜像数据与内存状态高度同步，最大程度地缩小了数据丢失风险窗口，优化了 \text{RPO} 至毫秒甚至亚毫秒级别。同时，快速落盘也意味着脏页能更快地从缓冲区中释放，避免了增量缓冲区对 $M_{\text{total}}$ 的无效占用，使系统始终保持轻量化运行状态。

\subsection{自适应收敛算法与双重触发机制}

为了将上述动态策略转化为可执行的工程逻辑，本研究设计了一套基于双重触发机制（容量触发 + 时间触发）的自适应算法。系统维护一个定时器$T_{\text{wait}}$ 和一个容量动态调整的增量缓冲区，并遵循以下状态流转规则对批大小进行弹性调节：

\textbf{规则一：容量超限触发时趋向懒惰}

\text{触发条件}：如果在定时器周期 $T_{\text{wait}}$ 到期之前，增量缓冲区就已经被脏页填满。

\text{机制判定}：这表明当前的脏页产生速率 $R_{\text{dirty}}$ 极快，频繁的 \text{I/O} 提交正在消耗大量 \text{CPU} 资源，系统已陷入拥塞状态。此时的首要目标是保护 $C_{\text{total}}$。

\text{动作}：系统立即执行落盘操作，并将下一周期的批大小翻倍。通过这种指数级增加批处理大小的方式，系统迅速降低了 I/O 中断频率，迫使 I/O 模式向“懒惰”侧收敛，以缓解 \text{CPU} 压力，实现一种资源回退策略。

\textbf{规则二：时间超时触发时趋向实时}

\text{触发条件}：如果定时器周期 $T_{\text{wait}}$ 耗尽，但缓冲区内的数据量仍未达到当前批大小的上限。

\text{机制判定}：这表明当前的写入压力较小，但系统为了凑满一个过大的批次而引入了不必要的等待延迟，影响了数据鲜度和 \text{RPO}。此时的首要目标是优化 \text{RPO}。

\text{动作}：系统强制执行落盘操作，并将下一周期的批大小减半。通过减小批处理大小，系统提升了落盘频率，迫使 \text{I/O} 模式向“实时”侧收敛。这种机制确保了在资源可用时，数据能尽快持久化，从而最大化利用闲置的 $B_{\text{io}}$ 资源，保障数据安全。

\textbf{规则三：边界收敛与弹性限制}

为了防止批大小在极端情况下无限制地震荡，算法设定了明确的上下界限制：在极度空闲时，批大小 收敛至 $1$ 个页面（$4\text{KB}$），此时算法退化为标准的实时写时复制，提供最优的数据鲜度；在极度繁忙时，批大小 收敛至预设的缓冲区上限（如 $2\text{MB}$），此时算法退化为纯批量处理模式，优先保障业务的生存与稳定性。通过这种弹性伸缩机制，\text{HPRO} 系统在微观的时间尺度上实现了对 \text{I/O} 提交频率的精细控制，从而在业务繁忙时“积少成多”以降低系统开销，在业务空闲时“快进快出”以保障数据安全。

通过这种弹性伸缩机制，HPRO 系统在微观的时间尺度上实现了对 I/O 提交频率的精细控制：在业务繁忙时“积少成多”以降低系统开销，在业务空闲时“快进快出”以保障数据安全。实验表明，这种策略在混合负载下能够显著降低快照过程对 CPU 的占用率，同时在空闲期将 RPO 缩短至毫秒级。

\section{本章小结}

本章针对嵌入式虚拟化环境资源受限且负载波动剧烈的特征，构建了 HPRO 系统的核心决策与调度引擎。

首先，承接第四章的热点识别成果，本章制定了基于热度感知的分级传输策略。该策略建立了从页面热度状态到传输行为的直接映射：将极热页推迟至停机阶段以避免无效传输，对温热页实施主动 COW 保护以确保一致性，对冷寂页进行后台异步传输以平摊 I/O 压力，并辅以异常兜底机制。这一策略确立了“动静分离”的传输基调，实现了快照流量的精细化分流 。

其次，为了解决快照在动态负载下的调度难题，本章建立了 SPI 模型。针对异构资源难以统一衡量的问题，该模型通过加权融合 CPU 负载、I/O 队列深度、内存水位及能源状态，为系统提供了一个能够实时量化当前负载压力的归一化数值 。
再次，基于 SPI 的实时反馈，本章设计了自适应的三级执行模式（高压、标准、低压）。系统能够根据负载压力动态调节热点判定的阈值与后台传输的速率，实现了在“业务优先”与“快照优先”策略间的平滑切换，避免了传统静态策略导致的资源死锁或带宽浪费 。

最后，针对连续快照场景，本章提出了动态增量策略。通过构建与 SPI 联动的动态批处理机制，系统能够在高负载下通过增大批大小减少 I/O 次数，在低负载下通过减小批大小提升数据实时性，有效平衡了 I/O 吞吐量与数据保护窗口之间的矛盾 。

通过上述机制的协同工作，本章完成了从“数据分级”到“资源调度”的完整逻辑闭环。然而，策略层发出的写入指令最终需要落地到物理存储介质上。针对嵌入式 Flash 存储介质固有的写放大效应与性能瓶颈，如何优化底层的 I/O 路径将在下一章进行详细阐述。

