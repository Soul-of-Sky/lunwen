% !TEX root = ../main.tex

% 定义英文摘要和关键字

\begin{eabstract}

The rapid evolution of artificial intelligence, edge computing, and lightweight cloud platforms has fundamentally shifted the landscape of computational deployment. We are increasingly seeing complex workloads—ranging from model inference to real-time control—migrating into heterogeneous environments that are strictly constrained by resources. Virtualization serves as the bedrock for these deployments; by leveraging lightweight virtual machines or isolated runtime instances, these systems effectively support a wide array of scenarios, including cloud-edge collaboration, unmanned systems, industrial control, and distributed intelligence.

In this context, operating system snapshots—primarily implemented as VM state snapshots—are indispensable for ensuring system consistency, enabling online migration, and facilitating fault tolerance. However, a significant disconnect exists. Traditional snapshot techniques were matured in the luxury of resource-abundant cloud servers. When we force these classic mechanisms (such as Stop-Copy, Pre-Copy and Post-Copy) down into environments defined by limited computation, tight memory, restricted bandwidth, and energy sensitivity, they often fail to deliver. The symptoms of this mismatch are severe: dirty page generation rates frequently outpace transmission speeds, preventing iteration convergence; high-frequency VM Exits and page fault handling introduce unacceptable latency; and aggressive background writes trigger Flash write amplification and I/O blocking. For AI inference scenarios specifically, this translates into amplified system jitter and a high risk of violating real-time constraints.

To address these specific challenges, this study proposes an optimization framework for OS snapshots, utilizing hotspot awareness and system resource feedback. Our design focuses specifically on the memory snapshot process within virtualized environments.

Our approach utilizes hardware-assisted dirty bits to construct a lightweight, adaptive multi-bit aging model. This allows us to capture the spatiotemporal locality of memory writes with negligible overhead, thereby precisely identifying "hot" memory regions. Furthermore, we define a System Pressure Index (SPI). By monitoring CPU load, I/O queue depth, memory usage, and energy status in real-time, the system adaptively modulates the page selection during downtime, regulates the pace of background migration, and optimizes batch strategies for incremental writes. Recognizing that these environments often rely on Flash storage, we also designed mechanisms for write merging, fine-grained deduplication, and token-bucket-based I/O throttling to mitigate write amplification and curb burst bandwidth usage.

Validation via a QEMU/KVM-based prototype demonstrates that our method maintains strong consistency of VM states while significantly reducing interference with AI inference and real-time tasks. We observed reduced downtime, smaller snapshot data volumes, and lower storage overhead. Ultimately, this research offers an efficient, scalable snapshot optimization solution for building high-availability virtualization infrastructure in the era of edge intelligence.
\end{eabstract}

\ekeywords{Operating System Snapshot, Virtualization Snapshot, Hotspot Perception, Re\-source-Constrained Environment}
